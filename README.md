# IPproxy

* 利用Python的aiohttp/re/beautifulsoup/tesseract等模块实现的代理IP池，并作数据持久化存储


## 注明

* 1.由于之前使用的国内代理网站好多改版或者已经不再运营，所以导致之前的代码已不可用，现在新增的是国外代理网站，所以你爬取的时候可能需要科学上网。你可能有疑惑了，我需要的是代理，但是获取这些代理前提是我得有代理，这不是很矛盾吗，非也，获取的代理是在代码上使用的，可以切换和多变，而你自用的科学上网工具是为了获取国外网站的信息，且ip基本固定
* 2.添加的国外代理响应速度不够快，容易导致【[Errno 54] Connection reset by peer】等异常提示，适当放慢速度或者timeout的值设置大一点即可，视具体情况而定
* 3.新增的代理也不知道后续能使用多久，也请不要过于频繁的请求别人平台，做免费代理不易
* 4.后续大概率是不会再更新本项目了，要长期使用，免费的不太理想，可用率低且时效性差，并且大多都是透明代理而非高匿的，容易被检测到


## 基本说明


* 本项目仅供个人开发者学习交流使用，请勿用于非法用途，否则后果自负

* 具体爬取结果根据当前使用计算机所在网络环境而定

* 抓取各大代理网站的免费代理，组建代理池，同时已自动附带主流UA(user-agent)池

* 代理有时效性，建议使用时检测代理可用性再使用，但同时建议爬取频率不要太频繁，如果因为恶意爬取将他人网站搞崩，后果自负

* 程序流程图
	+ [程序流程](http://naotu.baidu.com/file/b754a429094727b85240df587d005a3c?token=fd57d469e8309269)

## 更新进度：

### 2021/07/18更新

* 由于国内代理网站大部分已废弃，故删除并新增11个国外代理网站
* 使用aiohttp代替requests，aioredis代替redis
* 更新说明文档
* 已取消自动测试代理可用性功能，因为时效性过低，测试阶段意义不大
* 目前只有异步模式，其他模式已去掉


### 2019/11/27更新

* 去掉无效的代理网站，修改已有的代理解析规则，新增几个国内外代理网站，目前已经几乎覆盖了国内的所有免费代理网站
* 爬取结果较之前版本有提升 

### 2019/11/09更新

* 66ip网站已更新，无论怎么设置，每次请求都只能获取6个代理，导致最终结果大大减少，可用代理减少大半，正在寻求新的代理网站并解析，有新发现的朋友也可以提交分支

### 2019/10/23更新

* 对爬取的可用代理精准去重，保证唯一性

### 2019/7/30更新

* 破解66ip代理网站的加密字段，较之前能达到120个以上的可用代理


### 2019/7/29更新

* 增加更多的代理网站，以提高可用代理量

* 利用tessertact-ocr提取部分网站的数据

## 计划待更新的功能：


* requests库爬取数据时，还是无法解决访问请求时的阻塞情况，后期考虑使用aiohttp代替reqeuests



## 开发环境

* Python3.7
* aiohttp
* aioredis
* gevent
* lxml
* bs4
* json
* ThreadPoolExecutor
* flask
* pytesseract

* 安装必须的库

    ``pip install -r requirements.txt ``
    
## 相关说明：

* config.py
	+ 相关配置文件，里面主要是UA，代理网站链接，测试ip的网站，可以自己扩展，根据里面已有的数据格式添加即可
* headers.py
	+ 获取一个随机UA头，自动生成一个请求头
* proxy.py 
	+ 主要的逻辑代码，如果config文件代理网站有新增，自行定制对应的解析规则
* main.py
    + 以flask作为web服务启动文件

* 根据文字说明操作即可，分了三个方法，第一个是协程式，第二个是线程池，第三个是线程池+异步，自行选择

* 从数据库调取数据部分，分了两个方法测试代理可用性，第一个是线程池方法，第二个是线程池+异步方法，自行选择

## 运行：

* 因为爬取的代理网站众多，测试代理可用性也需要些时间，初次爬取代理时所耗时间平均在5-6分钟，后续取数据阶段则会很快

### 终端方式运行：

* 在运行之前自行安装配置redis数据库

* 在运行之前自行安装配置tesseract引擎

* 直接按proxy.py文件选择不同方法，取消相关的注释并运行proxy.py文件即可，config.py与headers.py请保证和proxy.py同在一目录下

### web方式运行：

* web方式运行调取的是从redis数据库中取出的数据，如果redis没有数据则先爬取数据再以web方式运行

* 启动main.py文件，用flask将结果以web页面的方式返回代理池，如果希望搭建在服务器上的话则可以此方式启动


#### 注：以web方式返回结果有点慢，因为为了保证返回的结果100%可用性，后台在自动测试代理可用性，如果对速度有要求，可以将相应的测试代码部分注释掉


## 运行结果：

### 数据库内无值时：

* 爬取部分：

![爬取](https://raw.githubusercontent.com/Eeyhan/pictures/master/proxy5.png)


* redis数据库结果：

![数据库获取](https://raw.githubusercontent.com/Eeyhan/pictures/master/redis.png)


### 数据库内有值时：

* 测试代理部分：

![测试代理](https://raw.githubusercontent.com/Eeyhan/pictures/master/proxy3.png)

* 将可用的重新再存入数据库：

![数据库内新的值](https://raw.githubusercontent.com/Eeyhan/pictures/master/proxy4.png)


### web方式启动结果：

![web页面启动](https://raw.githubusercontent.com/Eeyhan/pictures/master/flask.png)


## 自定制：

* 支持自己添加，自己重置UA，设置请求头

* 支持自己添加需要爬取的代理IP，config.py文件里有说明，自添加爬取的代理IP之后，需要自定制对应的方法，自己设置解析网站和测试代理IP的方法

* 支持NormalProxy类自定制，自扩展方法


## 更多技能点：

### [我的博客](https://www.cnblogs.com/Eeyhan '博客')